import gradio as gr
import os
from load_and_embed import load_vectorstore
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

# åˆæœŸåŒ–ï¼ˆæœ€åˆã®1å›ã®ã¿ï¼‰
vectorstore = load_vectorstore()

def answer_question(query):
    openai_api_key = os.environ.get("OPENAI_API_KEY")
    if not not openai_api_key:
        return "âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
    llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, openai_api_key=openai_api_key)
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=vectorstore.as_retriever())
    result = qa_chain.run(query)
    return result

demo = gr.Interface(fn=answer_question, 
                    inputs=gr.Textbox(lines=2, placeholder="è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"), 
                    outputs="text",
                    title="ğŸ“š ã‚ãªãŸã®æ›¸ç±ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ",
                    description="ã‚ãªãŸã®æœ¬ã®å†…å®¹ã«åŸºã¥ã„ã¦AIãŒç­”ãˆã¾ã™ã€‚")

demo.launch()